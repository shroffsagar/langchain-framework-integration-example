{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Router Chain Example\n",
    "\n",
    "This notebook demonstrates how to use LangChain's Router Chain to route queries to different specialized prompts based on the input type. The example implements a system that can:\n",
    "\n",
    "1. **Analyze Requirements**: Routes to a requirement analyst prompt that converts high-level product requirements into GHERKIN format acceptance criteria\n",
    "2. **Create Test Plans**: Routes to a tester prompt that develops comprehensive test strategies and plans\n",
    "3. **Generate Test Automation**: Routes to an automation expert prompt that converts manual test cases into automated tests using Playwright and Robot Framework\n",
    "\n",
    "## Key Components\n",
    "\n",
    "- Multiple specialized prompts for different roles\n",
    "- Router chain to determine which prompt to use\n",
    "- Example inputs showing the full workflow from requirements to test automation\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- OpenAI API key\n",
    "- LangChain library\n",
    "- Python environment with JupyterLab/Notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_1 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert on animals.\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_requirement_analyst = \"\"\"You are a requirement analyst who is great in understanding the high level product requirements, finding gaps or contradictory requirements, asking questions to fill in missing gaps, and finally documenting them in acceptance criteria in GHERKIN format in an organized way. You have over 20 years of experience in data processing / data analyst domain.\n",
    "\n",
    "Here is the high level product feature requirement:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "prompt_tester = \"\"\"You are an expert tester who is great in discovering edge cases and bugs. You come up with scenarios that are closer to customer usecases since you have over 20 years of experience in data processing (etl) domain. You would be provided with the findings of the business analyst and your main goal is to use product's acceptance criteria and come up with concrete test strategy and test plan for the given project. Do not just limit to the acceptance criteria but also consider other findings by the business analyst such as open questions, gaps etc. Keep track of any pending items in the test plan so that it is under radar. Remember, you are not just translating the acceptance crietria into test cases but also adding more value by coming up with more test cases that are not covered in the acceptance criteria since you are an expert tester.\n",
    "\n",
    "Here is the output of the business analyst:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "prompt_automation = \"\"\"You are an expert automation tester who is great in writing automated tests. You expertise lies in Playwright for e2e automated tests and Robot for api tests. Your main goal is to convert the manual tests into automated tests that are reliable and easy to maintain following test best practices. The tester would provide you with the complete test plan and strategy and you need to automate the documented tests in it. Automate the tests according to the test pyramid shifting left to api as much as possible with minimal e2e tests. Generate automated tests in different sections. \n",
    "\n",
    "Here is the output of the tester:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "prompts = [\n",
    "    {\n",
    "        \"name\": \"Requirement Analyst\",\n",
    "        \"description\": \"Expert in translating high level product requirements into acceptance criteria in Gherkin format\",\n",
    "        \"prompt_template\": prompt_requirement_analyst,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Tester\",\n",
    "        \"description\": \"Expert in writing test strategy and test plan using the acceptance criteria given for the given project\",\n",
    "        \"prompt_template\": prompt_tester,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Automation\",\n",
    "        \"description\": \"Expert in writing automated tests using playwright and ROBOT\",\n",
    "        \"prompt_template\": prompt_automation,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "OPEN_AI_KEY = subprocess.run('bash -l -c \"getpassw $OPEN_AI_API_KEY\"', shell=True, capture_output=True, text=True)\n",
    "OPEN_AI_KEY = OPEN_AI_KEY.stdout.strip()\n",
    "LLM_MODEL = \"gpt-4o-mini-2024-07-18\"\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, api_key=OPEN_AI_KEY, model=LLM_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt_chains = {}\n",
    "for p in prompts:\n",
    "    prompt_template = ChatPromptTemplate.from_template(template=p[\"prompt_template\"])\n",
    "    llmChain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    prompt_chains[p[\"name\"]] = llmChain\n",
    "\n",
    "prompt_name_and_description = \"\\n\".join([f\"{p['name']}: {p['description']}\" for p in prompts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.router.llm_router import RouterOutputParser, LLMRouterChain\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "\n",
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a language \\\n",
    "model, the model should be able to route to the correct prompt based \\\n",
    "on the input. You will be provided with the name of the prompts and \\\n",
    "high level purpose of the prompt in its description.\\\n",
    "\n",
    "Prompts:\n",
    "{prompt_name_and_description}\n",
    "\n",
    "Response Format/Output:\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string // The name of the prompt that user provided OR DEFAULT if no prompt is found\n",
    "    \"next_inputs\": string // The input that user provided\n",
    "}}}}\n",
    "```\n",
    "\n",
    "Input:\n",
    "{{input}}\n",
    "\"\"\"\n",
    "\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(prompt_name_and_description=prompt_name_and_description)\n",
    "router_prompt = PromptTemplate(template=router_template, \n",
    "                                 input_variables=[\"input\"],\n",
    "                                 output_parser=RouterOutputParser()\n",
    "                                )\n",
    "router_chain = LLMRouterChain.from_llm(llm=llm, prompt=router_prompt)\n",
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)\n",
    "chain = MultiPromptChain(router_chain = router_chain, \n",
    "                         destination_chains=prompt_chains,\n",
    "                         default_chain=default_chain, \n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement Analyst: {'input': 'Feature: A ETL tool to additionally support filtering of rows using new advance filter expression'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Requirements Analysis Output:\n",
      "To effectively analyze the high-level product requirement for the ETL tool that supports filtering of rows using a new advanced filter expression, we need to break down the requirement, identify potential gaps or contradictions, and formulate acceptance criteria in GHERKIN format.\n",
      "\n",
      "### High-Level Requirement Breakdown\n",
      "1. **Feature Overview**: The ETL tool should allow users to filter rows based on advanced filter expressions.\n",
      "2. **User Needs**: Users need the ability to define complex filtering criteria to refine the data being processed.\n",
      "3. **Functionality**: The filtering mechanism should support various logical and comparison operators, as well as functions for more advanced filtering.\n",
      "\n",
      "### Questions to Fill in Gaps\n",
      "1. **What types of data sources will the ETL tool support for filtering?**\n",
      "2. **What specific advanced filter expressions are expected? (e.g., AND, OR, NOT, etc.)**\n",
      "3. **Are there any limitations on the complexity of the filter expressions?**\n",
      "4. **Will users be able to save and reuse filter expressions?**\n",
      "5. **What is the expected performance impact of applying these filters?**\n",
      "6. **How will errors in filter expressions be handled?**\n",
      "7. **Is there a user interface component for defining these filters, or will it be done through code?**\n",
      "8. **What kind of user roles will have access to this feature?**\n",
      "\n",
      "### Acceptance Criteria in GHERKIN Format\n",
      "Based on the high-level requirement and the questions above, here are the acceptance criteria documented in GHERKIN format:\n",
      "\n",
      "```gherkin\n",
      "Feature: Advanced Row Filtering in ETL Tool\n",
      "\n",
      "  Scenario: User applies a simple filter expression\n",
      "    Given the user has access to the ETL tool\n",
      "    When the user defines a filter expression \"age > 30\"\n",
      "    Then the ETL tool should filter the rows where age is greater than 30\n",
      "\n",
      "  Scenario: User applies a complex filter expression\n",
      "    Given the user has access to the ETL tool\n",
      "    When the user defines a filter expression \"age > 30 AND country = 'USA'\"\n",
      "    Then the ETL tool should filter the rows where age is greater than 30 and country is 'USA'\n",
      "\n",
      "  Scenario: User uses logical operators in filter expressions\n",
      "    Given the user has access to the ETL tool\n",
      "    When the user defines a filter expression \"age < 20 OR (country = 'Canada' AND status = 'active')\"\n",
      "    Then the ETL tool should filter the rows where age is less than 20 or country is 'Canada' and status is 'active'\n",
      "\n",
      "  Scenario: User encounters an error in filter expression\n",
      "    Given the user has access to the ETL tool\n",
      "    When the user defines an invalid filter expression \"age >\"\n",
      "    Then the ETL tool should display an error message indicating the filter expression is invalid\n",
      "\n",
      "  Scenario: User saves a filter expression for future use\n",
      "    Given the user has access to the ETL tool\n",
      "    When the user defines a filter expression \"salary > 50000\"\n",
      "    And the user saves the filter expression as \"High Salary Filter\"\n",
      "    Then the filter expression \"High Salary Filter\" should be available for future use\n",
      "\n",
      "  Scenario: Performance of filtering is acceptable\n",
      "    Given the user has access to the ETL tool\n",
      "    When the user applies a filter expression on a dataset of 1 million rows\n",
      "    Then the filtering operation should complete within 5 seconds\n",
      "\n",
      "  Scenario: User interface for defining filter expressions\n",
      "    Given the user has access to the ETL tool\n",
      "    When the user navigates to the filter definition section\n",
      "    Then the user should see an interface that allows them to create and edit filter expressions using a visual editor\n",
      "```\n",
      "\n",
      "### Conclusion\n",
      "The above GHERKIN scenarios provide a structured way to validate the functionality of the advanced filtering feature in the ETL tool. Each scenario addresses different aspects of the requirement, ensuring comprehensive coverage of user needs and potential edge cases. Further discussions with stakeholders may be necessary to clarify any remaining gaps or ambiguities.\n"
     ]
    }
   ],
   "source": [
    "# Store chain outputs\n",
    "chain_outputs = {}\n",
    "\n",
    "# First chain run - Get requirements analysis\n",
    "chain_outputs['requirements'] = chain.run(\"Feature: A ETL tool to additionally support filtering of rows using new advance filter expression\")\n",
    "print(\"Requirements Analysis Output:\")\n",
    "print(chain_outputs['requirements'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tester: {'input': 'Generate the test plan for the requirements gather by the business analyst: To effectively analyze the high-level product requirement for the ETL tool that supports filtering of rows using a new advanced filter expression, we need to break down the requirement, identify potential gaps or contradictions, and formulate acceptance criteria in GHERKIN format.\\n\\n### High-Level Requirement Breakdown\\n1. **Feature Overview**: The ETL tool should allow users to filter rows based on advanced filter expressions.\\n2. **User Needs**: Users need the ability to define complex filtering criteria to refine the data being processed.\\n3. **Functionality**: The filtering mechanism should support various logical and comparison operators, as well as functions for more advanced filtering.\\n\\n### Questions to Fill in Gaps\\n1. **What types of data sources will the ETL tool support for filtering?**\\n2. **What specific advanced filter expressions are expected? (e.g., AND, OR, NOT, etc.)**\\n3. **Are there any limitations on the complexity of the filter expressions?**\\n4. **Will users be able to save and reuse filter expressions?**\\n5. **What is the expected performance impact of applying these filters?**\\n6. **How will errors in filter expressions be handled?**\\n7. **Is there a user interface component for defining these filters, or will it be done through code?**\\n8. **What kind of user roles will have access to this feature?**\\n\\n### Acceptance Criteria in GHERKIN Format\\nBased on the high-level requirement and the questions above, here are the acceptance criteria documented in GHERKIN format:\\n\\n```gherkin\\nFeature: Advanced Row Filtering in ETL Tool\\n\\n  Scenario: User applies a simple filter expression\\n    Given the user has access to the ETL tool\\n    When the user defines a filter expression \"age > 30\"\\n    Then the ETL tool should filter the rows where age is greater than 30\\n\\n  Scenario: User applies a complex filter expression\\n    Given the user has access to the ETL tool\\n    When the user defines a filter expression \"age > 30 AND country = \\'USA\\'\"\\n    Then the ETL tool should filter the rows where age is greater than 30 and country is \\'USA\\'\\n\\n  Scenario: User uses logical operators in filter expressions\\n    Given the user has access to the ETL tool\\n    When the user defines a filter expression \"age < 20 OR (country = \\'Canada\\' AND status = \\'active\\')\"\\n    Then the ETL tool should filter the rows where age is less than 20 or country is \\'Canada\\' and status is \\'active\\'\\n\\n  Scenario: User encounters an error in filter expression\\n    Given the user has access to the ETL tool\\n    When the user defines an invalid filter expression \"age >\"\\n    Then the ETL tool should display an error message indicating the filter expression is invalid\\n\\n  Scenario: User saves a filter expression for future use\\n    Given the user has access to the ETL tool\\n    When the user defines a filter expression \"salary > 50000\"\\n    And the user saves the filter expression as \"High Salary Filter\"\\n    Then the filter expression \"High Salary Filter\" should be available for future use\\n\\n  Scenario: Performance of filtering is acceptable\\n    Given the user has access to the ETL tool\\n    When the user applies a filter expression on a dataset of 1 million rows\\n    Then the filtering operation should complete within 5 seconds\\n\\n  Scenario: User interface for defining filter expressions\\n    Given the user has access to the ETL tool\\n    When the user navigates to the filter definition section\\n    Then the user should see an interface that allows them to create and edit filter expressions using a visual editor\\n```\\n\\n### Conclusion\\nThe above GHERKIN scenarios provide a structured way to validate the functionality of the advanced filtering feature in the ETL tool. Each scenario addresses different aspects of the requirement, ensuring comprehensive coverage of user needs and potential edge cases. Further discussions with stakeholders may be necessary to clarify any remaining gaps or ambiguities.'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Test Plan Output:\n",
      "### Test Plan for Advanced Row Filtering in ETL Tool\n",
      "\n",
      "#### 1. **Test Plan Overview**\n",
      "This test plan outlines the strategy and approach for testing the advanced filtering feature in the ETL tool. The goal is to ensure that the filtering functionality meets the acceptance criteria and addresses the user needs effectively while identifying potential edge cases and gaps.\n",
      "\n",
      "#### 2. **Objectives**\n",
      "- Validate the functionality of advanced filter expressions.\n",
      "- Ensure the user interface is intuitive and meets user expectations.\n",
      "- Assess performance under various data loads.\n",
      "- Identify and handle error scenarios gracefully.\n",
      "- Confirm that saved filter expressions can be reused effectively.\n",
      "\n",
      "#### 3. **Scope of Testing**\n",
      "- **In-Scope**:\n",
      "  - Functionality of filter expressions (simple and complex).\n",
      "  - Logical and comparison operators.\n",
      "  - User interface for filter definition.\n",
      "  - Error handling for invalid expressions.\n",
      "  - Performance testing with large datasets.\n",
      "  - Saving and reusing filter expressions.\n",
      "\n",
      "- **Out-of-Scope**:\n",
      "  - Integration with external systems (unless directly related to filtering).\n",
      "  - Non-filtering related features of the ETL tool.\n",
      "\n",
      "#### 4. **Test Strategy**\n",
      "- **Types of Testing**:\n",
      "  - **Functional Testing**: Validate that the filtering works as expected based on the acceptance criteria.\n",
      "  - **Usability Testing**: Ensure the user interface is user-friendly and intuitive.\n",
      "  - **Performance Testing**: Measure the time taken to filter large datasets.\n",
      "  - **Error Handling Testing**: Verify that appropriate error messages are displayed for invalid filter expressions.\n",
      "  - **Regression Testing**: Ensure that existing functionalities are not broken by the new feature.\n",
      "\n",
      "#### 5. **Test Environment**\n",
      "- ETL tool deployed in a staging environment with access to various data sources.\n",
      "- Test data sets of varying sizes (small, medium, large, and very large datasets).\n",
      "\n",
      "#### 6. **Test Cases**\n",
      "Based on the acceptance criteria and additional considerations, the following test cases will be executed:\n",
      "\n",
      "1. **Basic Functionality Tests**:\n",
      "   - Apply simple filter expressions (e.g., \"age > 30\").\n",
      "   - Apply complex filter expressions (e.g., \"age > 30 AND country = 'USA'\").\n",
      "   - Use logical operators in filter expressions (e.g., \"age < 20 OR (country = 'Canada' AND status = 'active')\").\n",
      "\n",
      "2. **Error Handling Tests**:\n",
      "   - Define an invalid filter expression (e.g., \"age >\") and verify error message.\n",
      "   - Define a filter expression with unsupported operators and verify error message.\n",
      "\n",
      "3. **Usability Tests**:\n",
      "   - Navigate to the filter definition section and verify the presence of a visual editor.\n",
      "   - Test the ease of creating and editing filter expressions using the UI.\n",
      "\n",
      "4. **Performance Tests**:\n",
      "   - Apply filter expressions on datasets of varying sizes (1,000, 10,000, 100,000, 1,000,000 rows) and measure response time.\n",
      "   - Test performance with concurrent users applying filters simultaneously.\n",
      "\n",
      "5. **Save and Reuse Tests**:\n",
      "   - Save a filter expression and verify it is available for future use.\n",
      "   - Edit a saved filter expression and verify changes are reflected.\n",
      "\n",
      "6. **Edge Case Tests**:\n",
      "   - Test with boundary values (e.g., age = 30).\n",
      "   - Test with special characters in filter expressions (e.g., \"name = 'O'Reilly'\").\n",
      "   - Test with null or empty values in filter expressions.\n",
      "\n",
      "#### 7. **Pending Items / Open Questions**\n",
      "- Clarification on the types of data sources supported for filtering.\n",
      "- Confirmation on the specific advanced filter expressions expected.\n",
      "- Definition of limitations on the complexity of filter expressions.\n",
      "- User roles and permissions related to filter access.\n",
      "- Expected performance benchmarks for different data sizes.\n",
      "\n",
      "#### 8. **Risk Assessment**\n",
      "- **High Risk**: Performance issues with large datasets could impact user experience.\n",
      "- **Medium Risk**: Usability issues may lead to user frustration if the interface is not intuitive.\n",
      "- **Low Risk**: Error handling may not cover all edge cases, leading to potential confusion.\n",
      "\n",
      "#### 9. **Test Schedule**\n",
      "- **Test Preparation**: [Insert Dates]\n",
      "- **Test Execution**: [Insert Dates]\n",
      "- **Test Closure**: [Insert Dates]\n",
      "\n",
      "#### 10. **Reporting**\n",
      "- Test results will be documented and reported to stakeholders.\n",
      "- Any defects identified will be logged in the defect tracking system.\n",
      "\n",
      "### Conclusion\n",
      "This test plan provides a comprehensive approach to validating the advanced filtering feature in the ETL tool. By addressing both the acceptance criteria and additional considerations, we aim to ensure a robust and user-friendly implementation that meets the needs of the users effectively. Regular communication with stakeholders will be essential to address any pending items and clarify open questions.\n"
     ]
    }
   ],
   "source": [
    "# Second chain run - Get test plan using requirements output\n",
    "chain_outputs['test_plan'] = chain.run(f\"\"\"\n",
    "Generate the test plan for the requirements gather by the business analyst:\n",
    "{chain_outputs['requirements']}\n",
    "\"\"\")\n",
    "print(\"\\nTest Plan Output:\")\n",
    "print(chain_outputs['test_plan'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automation: {'input': 'Automated the tests provided in this test plan:\\n### Test Plan for Advanced Row Filtering in ETL Tool\\n\\n#### 1. **Test Plan Overview**\\nThis test plan outlines the strategy and approach for testing the advanced filtering feature in the ETL tool. The goal is to ensure that the filtering functionality meets the acceptance criteria and addresses the user needs effectively while identifying potential edge cases and gaps.\\n\\n#### 2. **Objectives**\\n- Validate the functionality of advanced filter expressions.\\n- Ensure the user interface is intuitive and meets user expectations.\\n- Assess performance under various data loads.\\n- Identify and handle error scenarios gracefully.\\n- Confirm that saved filter expressions can be reused effectively.\\n\\n#### 3. **Scope of Testing**\\n- **In-Scope**:\\n  - Functionality of filter expressions (simple and complex).\\n  - Logical and comparison operators.\\n  - User interface for filter definition.\\n  - Error handling for invalid expressions.\\n  - Performance testing with large datasets.\\n  - Saving and reusing filter expressions.\\n\\n- **Out-of-Scope**:\\n  - Integration with external systems (unless directly related to filtering).\\n  - Non-filtering related features of the ETL tool.\\n\\n#### 4. **Test Strategy**\\n- **Types of Testing**:\\n  - **Functional Testing**: Validate that the filtering works as expected based on the acceptance criteria.\\n  - **Usability Testing**: Ensure the user interface is user-friendly and intuitive.\\n  - **Performance Testing**: Measure the time taken to filter large datasets.\\n  - **Error Handling Testing**: Verify that appropriate error messages are displayed for invalid filter expressions.\\n  - **Regression Testing**: Ensure that existing functionalities are not broken by the new feature.\\n\\n#### 5. **Test Environment**\\n- ETL tool deployed in a staging environment with access to various data sources.\\n- Test data sets of varying sizes (small, medium, large, and very large datasets).\\n\\n#### 6. **Test Cases**\\nBased on the acceptance criteria and additional considerations, the following test cases will be executed:\\n\\n1. **Basic Functionality Tests**:\\n   - Apply simple filter expressions (e.g., \"age > 30\").\\n   - Apply complex filter expressions (e.g., \"age > 30 AND country = \\'USA\\'\").\\n   - Use logical operators in filter expressions (e.g., \"age < 20 OR (country = \\'Canada\\' AND status = \\'active\\')\").\\n\\n2. **Error Handling Tests**:\\n   - Define an invalid filter expression (e.g., \"age >\") and verify error message.\\n   - Define a filter expression with unsupported operators and verify error message.\\n\\n3. **Usability Tests**:\\n   - Navigate to the filter definition section and verify the presence of a visual editor.\\n   - Test the ease of creating and editing filter expressions using the UI.\\n\\n4. **Performance Tests**:\\n   - Apply filter expressions on datasets of varying sizes (1,000, 10,000, 100,000, 1,000,000 rows) and measure response time.\\n   - Test performance with concurrent users applying filters simultaneously.\\n\\n5. **Save and Reuse Tests**:\\n   - Save a filter expression and verify it is available for future use.\\n   - Edit a saved filter expression and verify changes are reflected.\\n\\n6. **Edge Case Tests**:\\n   - Test with boundary values (e.g., age = 30).\\n   - Test with special characters in filter expressions (e.g., \"name = \\'O\\'Reilly\\'\").\\n   - Test with null or empty values in filter expressions.\\n\\n#### 7. **Pending Items / Open Questions**\\n- Clarification on the types of data sources supported for filtering.\\n- Confirmation on the specific advanced filter expressions expected.\\n- Definition of limitations on the complexity of filter expressions.\\n- User roles and permissions related to filter access.\\n- Expected performance benchmarks for different data sizes.\\n\\n#### 8. **Risk Assessment**\\n- **High Risk**: Performance issues with large datasets could impact user experience.\\n- **Medium Risk**: Usability issues may lead to user frustration if the interface is not intuitive.\\n- **Low Risk**: Error handling may not cover all edge cases, leading to potential confusion.\\n\\n#### 9. **Test Schedule**\\n- **Test Preparation**: [Insert Dates]\\n- **Test Execution**: [Insert Dates]\\n- **Test Closure**: [Insert Dates]\\n\\n#### 10. **Reporting**\\n- Test results will be documented and reported to stakeholders.\\n- Any defects identified will be logged in the defect tracking system.\\n\\n### Conclusion\\nThis test plan provides a comprehensive approach to validating the advanced filtering feature in the ETL tool. By addressing both the acceptance criteria and additional considerations, we aim to ensure a robust and user-friendly implementation that meets the needs of the users effectively. Regular communication with stakeholders will be essential to address any pending items and clarify open questions.'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Test Automation Output:\n",
      "Based on the provided test plan for the advanced row filtering feature in the ETL tool, I will create automated tests using Playwright for end-to-end (E2E) testing and Robot Framework for API testing. The tests will be structured according to the test pyramid, focusing on API tests where possible and minimizing E2E tests.\n",
      "\n",
      "### Automated Tests Overview\n",
      "\n",
      "#### 1. **API Tests (Robot Framework)**\n",
      "\n",
      "**Directory Structure:**\n",
      "```\n",
      "tests/\n",
      "  ├── api/\n",
      "  │   ├── filter_tests.robot\n",
      "  └── e2e/\n",
      "      ├── filter_e2e.spec.ts\n",
      "```\n",
      "\n",
      "**Robot Framework API Tests: `filter_tests.robot`**\n",
      "```robot\n",
      "*** Settings ***\n",
      "Library           RequestsLibrary\n",
      "Library           Collections\n",
      "\n",
      "*** Variables ***\n",
      "${BASE_URL}      http://staging.etltool/api\n",
      "\n",
      "*** Test Cases ***\n",
      "Basic Functionality Tests\n",
      "    [Documentation]    Validate basic filter expressions\n",
      "    Apply Simple Filter Expression\n",
      "    Apply Complex Filter Expression\n",
      "    Apply Logical Operators\n",
      "\n",
      "Error Handling Tests\n",
      "    [Documentation]    Validate error handling for invalid expressions\n",
      "    Invalid Filter Expression\n",
      "    Unsupported Operator\n",
      "\n",
      "Save and Reuse Tests\n",
      "    [Documentation]    Validate saving and reusing filter expressions\n",
      "    Save Filter Expression\n",
      "    Edit Saved Filter Expression\n",
      "\n",
      "*** Keywords ***\n",
      "Apply Simple Filter Expression\n",
      "    ${response}=    GET    ${BASE_URL}/filter?expression=age>30\n",
      "    Should Be Equal As Numbers    ${response.status_code}    200\n",
      "    Should Contain    ${response.json()}    \"results\"\n",
      "\n",
      "Apply Complex Filter Expression\n",
      "    ${response}=    GET    ${BASE_URL}/filter?expression=age>30 AND country='USA'\n",
      "    Should Be Equal As Numbers    ${response.status_code}    200\n",
      "    Should Contain    ${response.json()}    \"results\"\n",
      "\n",
      "Apply Logical Operators\n",
      "    ${response}=    GET    ${BASE_URL}/filter?expression=age<20 OR (country='Canada' AND status='active')\n",
      "    Should Be Equal As Numbers    ${response.status_code}    200\n",
      "    Should Contain    ${response.json()}    \"results\"\n",
      "\n",
      "Invalid Filter Expression\n",
      "    ${response}=    GET    ${BASE_URL}/filter?expression=age>\n",
      "    Should Be Equal As Numbers    ${response.status_code}    400\n",
      "    Should Contain    ${response.json()}    \"error\"\n",
      "\n",
      "Unsupported Operator\n",
      "    ${response}=    GET    ${BASE_URL}/filter?expression=age>>30\n",
      "    Should Be Equal As Numbers    ${response.status_code}    400\n",
      "    Should Contain    ${response.json()}    \"error\"\n",
      "\n",
      "Save Filter Expression\n",
      "    ${response}=    POST    ${BASE_URL}/filter/save    {\"expression\": \"age>30\"}\n",
      "    Should Be Equal As Numbers    ${response.status_code}    201\n",
      "\n",
      "Edit Saved Filter Expression\n",
      "    ${response}=    PUT    ${BASE_URL}/filter/edit/1    {\"expression\": \"age>35\"}\n",
      "    Should Be Equal As Numbers    ${response.status_code}    200\n",
      "```\n",
      "\n",
      "#### 2. **E2E Tests (Playwright)**\n",
      "\n",
      "**Playwright E2E Tests: `filter_e2e.spec.ts`**\n",
      "```typescript\n",
      "import { test, expect } from '@playwright/test';\n",
      "\n",
      "test.describe('Advanced Row Filtering E2E Tests', () => {\n",
      "    test.beforeEach(async ({ page }) => {\n",
      "        await page.goto('http://staging.etltool');\n",
      "    });\n",
      "\n",
      "    test('Basic Functionality - Apply Simple Filter', async ({ page }) => {\n",
      "        await page.fill('input[name=\"filter\"]', 'age > 30');\n",
      "        await page.click('button#apply-filter');\n",
      "        const results = await page.locator('.results').innerText();\n",
      "        expect(results).toContain('Expected Result');\n",
      "    });\n",
      "\n",
      "    test('Error Handling - Invalid Filter Expression', async ({ page }) => {\n",
      "        await page.fill('input[name=\"filter\"]', 'age >');\n",
      "        await page.click('button#apply-filter');\n",
      "        const errorMessage = await page.locator('.error-message').innerText();\n",
      "        expect(errorMessage).toContain('Invalid filter expression');\n",
      "    });\n",
      "\n",
      "    test('Usability - Visual Editor Presence', async ({ page }) => {\n",
      "        await page.click('button#open-filter-editor');\n",
      "        const editorVisible = await page.isVisible('.filter-editor');\n",
      "        expect(editorVisible).toBe(true);\n",
      "    });\n",
      "\n",
      "    test('Performance - Filter Large Dataset', async ({ page }) => {\n",
      "        await page.fill('input[name=\"filter\"]', 'age > 30');\n",
      "        const startTime = Date.now();\n",
      "        await page.click('button#apply-filter');\n",
      "        const endTime = Date.now();\n",
      "        const duration = endTime - startTime;\n",
      "        expect(duration).toBeLessThan(2000); // Example threshold\n",
      "    });\n",
      "\n",
      "    test('Save and Reuse - Save Filter Expression', async ({ page }) => {\n",
      "        await page.fill('input[name=\"filter\"]', 'age > 30');\n",
      "        await page.click('button#save-filter');\n",
      "        const successMessage = await page.locator('.success-message').innerText();\n",
      "        expect(successMessage).toContain('Filter saved successfully');\n",
      "    });\n",
      "});\n",
      "```\n",
      "\n",
      "### Summary of Automated Tests\n",
      "\n",
      "- **API Tests**: Focus on validating the functionality of filter expressions, error handling, and saving/reusing filters using Robot Framework. This allows for quick feedback on the backend logic without the overhead of UI interactions.\n",
      "  \n",
      "- **E2E Tests**: Cover critical user interactions and usability aspects using Playwright. These tests ensure that the user interface behaves as expected and that the application can handle user inputs correctly.\n",
      "\n",
      "### Best Practices Followed\n",
      "- **Test Pyramid**: Prioritized API tests to cover business logic and reduced reliance on E2E tests.\n",
      "- **Maintainability**: Organized tests into clear sections and used descriptive names for test cases and keywords.\n",
      "- **Error Handling**: Included tests for invalid inputs to ensure robustness.\n",
      "- **Performance Considerations**: Incorporated performance tests to validate response times under load.\n",
      "\n",
      "This structure will help ensure that the advanced filtering feature in the ETL tool is thoroughly tested, reliable, and maintainable.\n"
     ]
    }
   ],
   "source": [
    "# Third chain run - Get test automation using test plan output\n",
    "chain_outputs['automation'] = chain.run(f\"\"\"\n",
    "Automated the tests provided in this test plan:\n",
    "{chain_outputs['test_plan']}\n",
    "\"\"\")\n",
    "print(\"\\nTest Automation Output:\")\n",
    "print(chain_outputs['automation'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
