{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "### Purpose of this Notebook\n",
    "\n",
    "This notebook demonstrates the use of various tools and libraries to interact with OpenAI's language models and LangChain for natural language processing tasks. The key objectives include:\n",
    "\n",
    "1. **Setting up OpenAI API**: Installing necessary packages, retrieving API keys, and initializing the OpenAI client.\n",
    "2. **Creating and using chat functions**: Defining functions to interact with the language model for generating responses based on user prompts.\n",
    "3. **Translating text styles**: Using the language model to translate text into different styles.\n",
    "4. **LangChain Integration**: Installing and using LangChain to create structured prompts and parse responses from the language model.\n",
    "5. **Output Parsing**: Defining response schemas and using LangChain formatters to automatically generate and parse structured outputs from the language model.\n",
    "6. **Extracting insights from customer reviews**: Formatting prompts to extract specific information from customer reviews and parsing the model's responses into structured data.\n",
    "\n",
    "This notebook provides examples of how to leverage OpenAI's language models and LangChain for various NLP tasks, including text translation, structured output generation, and information extraction.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv\n",
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "OPEN_AI_KEY = subprocess.run('bash -l -c \"getpassw $OPEN_AI_API_KEY\"', shell=True, capture_output=True, text=True)\n",
    "OPEN_AI_KEY = OPEN_AI_KEY.stdout.strip()\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=OPEN_AI_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL = \"gpt-4o-mini-2024-07-18\"\n",
    "def chat(prompt, model=LLM_MODEL):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 + 1 equals 2.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"what is 1 +    1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks \n",
      "into a style that is American English in a calm and respectful tone\n",
      "\n",
      "text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am quite frustrated that the lid of my blender came off and splattered my kitchen walls with smoothie. To make matters worse, the warranty does not cover the cost of cleaning up my kitchen. I would really appreciate your assistance with this issue. Thank you!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat API : LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain-openai\n",
    "%pip install langchain_community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(temperature=0.0, model=LLM_MODEL, openai_api_key=OPEN_AI_KEY)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is {style} text: ```{text}````\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style} \\\n",
    "text: ```{text}````\n",
    "\"\"\"\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['style', 'text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style} text: ```{text}````\\n'))]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "chat_prompt_template = ChatPromptTemplate.from_template(prompt_template)\n",
    "print(chat_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style} text: ```{text}````\\n')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\"\n",
    "\n",
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "customer_messages = chat_prompt_template.format_messages(style=style, text=customer_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\n",
      " text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "````\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(customer_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='I’m quite frustrated that the lid of my blender came off and splattered smoothie all over my kitchen walls. To make matters worse, the warranty doesn’t cover the cost of cleaning up my kitchen. I would really appreciate your assistance with this issue. Thank you!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 87, 'total_tokens': 141, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None} id='run-25d717fd-67b7-4fa1-8f30-35082e88fbaa-0' usage_metadata={'input_tokens': 87, 'output_tokens': 54, 'total_tokens': 141}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_reply = \"\"\"Hey there customer, \\\n",
    "the warranty does not cover \\\n",
    "cleaning expenses for your kitchen \\\n",
    "because it's your fault that \\\n",
    "you misused your blender \\\n",
    "by forgetting to put the lid on before \\\n",
    "starting the blender. \\\n",
    "Tough luck! See ya!\n",
    "\"\"\"\n",
    "\n",
    "service_style_pirate = \"\"\"\\\n",
    "a polite tone \\\n",
    "that speaks in English Pirate\\\n",
    "\"\"\"\n",
    "\n",
    "service_messages = chat_prompt_template.format_messages(style=service_style_pirate, text=service_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=\"Translate the text that is delimited by triple backticks into a style that is a polite tone that speaks in English Pirate text: ```Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! See ya!\\n````\\n\")]\n"
     ]
    }
   ],
   "source": [
    "print(service_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_response = chat(service_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahoy there, esteemed customer! I must inform ye that the warranty be not coverin' the expenses for cleanin' yer galley, as it be yer own misfortune that ye forgot to secure the lid upon yer blender before settin' it to whirl. Aye, 'tis a tough break! Fair winds to ye, and until we meet again!\n"
     ]
    }
   ],
   "source": [
    "print(service_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LangChain Output Parser to parse the output of the llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the customer_review delimited by triple backticks, extract the following information: \n",
      "gift: Was this item a gift for someone else? Answer True if yes and False if otherwise. \n",
      "delivery_time: How many days did it take for the item to arrive? Answer with a number, and if the item has not arrived or if it is not known then answer with -1. \n",
      "price: Extract the sentences about value or price and output the amounts in a comma sep python list. \n",
      "Format the output as a JSON object with following keys: gift, delivery_time, price. \n",
      "customer_review: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the customer_review delimited by triple backticks, \\\n",
    "extract the following information: \\\n",
    "\n",
    "gift: Was this item a gift for someone else? \\\n",
    "Answer True if yes and False if otherwise. \\\n",
    "\n",
    "delivery_time: How many days did it take for the item to arrive? \\\n",
    "Answer with a number, and if the item has not arrived or if it is not known then answer with -1. \\\n",
    "\n",
    "price: Extract the sentences about value or price \\\n",
    "and output the amounts in a comma sep python list. \\\n",
    "\n",
    "Format the output as a JSON object with following keys: \\\n",
    "gift, delivery_time, price. \\\n",
    "\n",
    "customer_review: {customer_review}\n",
    "\"\"\"\n",
    "\n",
    "customer_review_template = ChatPromptTemplate.from_template(review_template)\n",
    "get_insights_from_customer_review = customer_review_template.format_messages(customer_review=customer_review)\n",
    "print(get_insights_from_customer_review[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(get_insights_from_customer_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"gift\": true,\n",
      "  \"delivery_time\": 2,\n",
      "  \"price\": [\"slightly more expensive\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain Formatters allows to format the llm output directly\n",
    "#### We have to define the response schema and use LangChain formatters to automatically generate the response prompt for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "gift_schema = ResponseSchema(name= \"gift\", type=\"boolean\", \n",
    "                             description=(\n",
    "                                \"Was this item a gift for someone else? \"\n",
    "                                \"Answer True if yes and False if otherwise. \" \n",
    "                             )\n",
    ")\n",
    "delivery_time_schema = ResponseSchema(name= \"delivery_time\", type=\"integer\", \n",
    "                             description=(\n",
    "                              \"How many days did it took for the item to be delivered? \"\n",
    "                              \"Answer -1 if you don't know or if the item has not arrived yet. \"   \n",
    "                             ) \n",
    ")\n",
    "\n",
    "price_schema = ResponseSchema(name=\"price\", type=\"json\", \n",
    "                             description=(\n",
    "                                 \"First analyze the customer's opinion \"\n",
    "                                 \"by extracting the sentences related to price or value. \"\n",
    "                                 \"Then, assess whether the customer finds the product expensive, moderate or affordable. \"\n",
    "                                 \"Ensure that your final conclusion should reflect the customer's true attitude specifically towards price, taking into account any justification or perceived worth. \"\n",
    "                                 \"Answer with a final conclusion (expensive, moderate or affordable) and reason for conclusion in a JSON object with keys conclusion, reason_for_conclusion. \"\n",
    "                             )\n",
    ")\n",
    "output_format_instructions = StructuredOutputParser.from_response_schemas([gift_schema, delivery_time_schema, price_schema])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": boolean  // Was this item a gift for someone else? Answer True if yes and False if otherwise. \n",
      "\t\"delivery_time\": integer  // How many days did it took for the item to be delivered? Answer -1 if you don't know or if the item has not arrived yet. \n",
      "\t\"price\": json  // First analyze the customer's opinion by extracting the sentences related to price or value. Then, assess whether the customer finds the product expensive, moderate or affordable. Ensure that your final conclusion should reflect the customer's true attitude specifically towards price, taking into account any justification or perceived worth. Answer with a final conclusion (expensive, moderate or affordable) and reason for conclusion in a JSON object with keys conclusion, reason_for_conclusion. \n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(output_format_instructions.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the customer_review delimited by triple backticks, \\\n",
    "extract the following information: \\\n",
    "\n",
    "gift: {gift_instruction}\n",
    "\n",
    "delivery_time: {delivery_time_instruction}\n",
    "\n",
    "price: {price_instruction}\n",
    "\n",
    "Format the output as a JSON object with following keys: \\\n",
    "gift, delivery_time, price. \\\n",
    "\n",
    "customer_review: {customer_review}\n",
    "\n",
    "{output_format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "customer_review_template = ChatPromptTemplate.from_template(review_template)\n",
    "\n",
    "get_insights_from_customer_review = \\\n",
    "    customer_review_template.format_messages(\n",
    "        gift_instruction=gift_schema.description,\n",
    "        delivery_time_instruction=delivery_time_schema.description,\n",
    "        price_instruction=price_schema.description,\n",
    "        customer_review=customer_review,\n",
    "        output_format_instructions=output_format_instructions.get_format_instructions()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the customer_review delimited by triple backticks, extract the following information: \n",
      "gift: Was this item a gift for someone else? Answer True if yes and False if otherwise. \n",
      "\n",
      "delivery_time: How many days did it took for the item to be delivered? Answer -1 if you don't know or if the item has not arrived yet. \n",
      "\n",
      "price: First analyze the customer's opinion by extracting the sentences related to price or value. Then, assess whether the customer finds the product expensive, moderate or affordable. Ensure that your final conclusion should reflect the customer's true attitude specifically towards price, taking into account any justification or perceived worth. Answer with a final conclusion (expensive, moderate or affordable) and reason for conclusion in a JSON object with keys conclusion, reason_for_conclusion. \n",
      "\n",
      "Format the output as a JSON object with following keys: gift, delivery_time, price. \n",
      "customer_review: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": boolean  // Was this item a gift for someone else? Answer True if yes and False if otherwise. \n",
      "\t\"delivery_time\": integer  // How many days did it took for the item to be delivered? Answer -1 if you don't know or if the item has not arrived yet. \n",
      "\t\"price\": json  // First analyze the customer's opinion by extracting the sentences related to price or value. Then, assess whether the customer finds the product expensive, moderate or affordable. Ensure that your final conclusion should reflect the customer's true attitude specifically towards price, taking into account any justification or perceived worth. Answer with a final conclusion (expensive, moderate or affordable) and reason for conclusion in a JSON object with keys conclusion, reason_for_conclusion. \n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_insights_from_customer_review[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(get_insights_from_customer_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"gift\": true,\n",
      "\t\"delivery_time\": 2,\n",
      "\t\"price\": {\n",
      "\t\t\"conclusion\": \"expensive\",\n",
      "\t\t\"reason_for_conclusion\": \"The customer mentions that it is slightly more expensive than other leaf blowers, indicating a perception of higher cost compared to alternatives.\"\n",
      "\t}\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "customer_review_obj = output_format_instructions.parse(response.content)\n",
    "print(type(customer_review_obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "{'conclusion': 'expensive', 'reason_for_conclusion': 'The customer mentions that it is slightly more expensive than other leaf blowers, indicating a perception of higher cost compared to alternatives.'}\n"
     ]
    }
   ],
   "source": [
    "print(customer_review_obj[\"gift\"])\n",
    "print(customer_review_obj[\"delivery_time\"])\n",
    "print(customer_review_obj[\"price\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
